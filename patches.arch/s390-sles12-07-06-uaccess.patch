From: Heiko Carstens <heiko.carstens@de.ibm.com>
Subject: s390/uaccess: normalize order of parameters of indirect uaccess function calls
Patch-mainline: v3.15-rc1
Git-commit: cfa785e623577cdad2aa721acb23bd3a95eced9a
References: bnc#878391, LTC#110601

Description:  kernel: remove page table walk for user space accesses
Symptom:      Unexpected program crashes, random data corruption.
Problem:      The user space access functions perform page table walks in order
              to translate a user space virtual address to a physical address.
              While doing that the kernel must make sure the page table can not
              be changed concurrently from a different cpu.
              Therefore the page table lock must be held. However instead of
              acquiring the per page table split page table lock the kernel
              incorrectly acquired the per mm global page table lock.
              This allows different cpus to modify the page table contents
              while its contents are inspected and being used to access the
              corresponding user space address space.
              Therefore the kernel may access a page which was concurrently
              freed on a different cpu, which can lead to data corruption.
              This problem exists only for futex operations.
Solution:     Remove page table walks and rework the user space access code to
              use machine instructions to access user space. This avoids all
              locking issues.
Reproduction: -

Upstream-Description:

              s390/uaccess: normalize order of parameters of indirect uaccess function calls

              For some unknown reason the indirect uaccess functions on s390 implement a
              different parameter order than what is usual.

              e.g.:

              unsigned long copy_to_user(void *to, const void *from, unsigned long n);
              vs.
              size_t (*copy_to_user)(size_t n, void __user * to, const void *from);

              Let's get rid of this confusing parameter reordering.

              Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
              Signed-off-by: Martin Schwidefsky <schwidefsky@de.ibm.com>


Signed-off-by: Heiko Carstens <heiko.carstens@de.ibm.com>
Acked-by: John Jolly <jjolly@suse.de>
---
 arch/s390/include/asm/uaccess.h |   54 ++++++++++++++++++++--------------------
 arch/s390/lib/uaccess_mvcos.c   |   20 +++++++-------
 arch/s390/lib/uaccess_pt.c      |   34 ++++++++++++-------------
 3 files changed, 54 insertions(+), 54 deletions(-)

--- a/arch/s390/include/asm/uaccess.h
+++ b/arch/s390/include/asm/uaccess.h
@@ -93,12 +93,12 @@ static inline unsigned long extable_fixu
 #define ARCH_HAS_SEARCH_EXTABLE
 
 struct uaccess_ops {
-	size_t (*copy_from_user)(size_t, const void __user *, void *);
-	size_t (*copy_to_user)(size_t, void __user *, const void *);
-	size_t (*copy_in_user)(size_t, void __user *, const void __user *);
-	size_t (*clear_user)(size_t, void __user *);
-	size_t (*strnlen_user)(size_t, const char __user *);
-	size_t (*strncpy_from_user)(size_t, const char __user *, char *);
+	size_t (*copy_from_user)(void *, const void __user *, size_t);
+	size_t (*copy_to_user)(void __user *, const void *, size_t);
+	size_t (*copy_in_user)(void __user *, const void __user *, size_t);
+	size_t (*clear_user)(void __user *, size_t);
+	size_t (*strnlen_user)(const char __user *, size_t);
+	size_t (*strncpy_from_user)(char *, const char __user *, size_t);
 	int (*futex_atomic_op)(int op, u32 __user *, int oparg, int *old);
 	int (*futex_atomic_cmpxchg)(u32 *, u32 __user *, u32 old, u32 new);
 };
@@ -109,15 +109,15 @@ extern struct uaccess_ops uaccess_pt;
 
 extern int __handle_fault(unsigned long, unsigned long, int);
 
-static inline int __put_user_fn(size_t size, void __user *ptr, void *x)
+static inline int __put_user_fn(void *x, void __user *ptr, size_t size)
 {
-	size = uaccess.copy_to_user(size, ptr, x);
+	size = uaccess.copy_to_user(ptr, x, size);
 	return size ? -EFAULT : size;
 }
 
-static inline int __get_user_fn(size_t size, const void __user *ptr, void *x)
+static inline int __get_user_fn(void *x, const void __user *ptr, size_t size)
 {
-	size = uaccess.copy_from_user(size, ptr, x);
+	size = uaccess.copy_from_user(x, ptr, size);
 	return size ? -EFAULT : size;
 }
 
@@ -135,8 +135,8 @@ static inline int __get_user_fn(size_t s
 	case 2:							\
 	case 4:							\
 	case 8:							\
-		__pu_err = __put_user_fn(sizeof (*(ptr)),	\
-					 ptr, &__x);		\
+		__pu_err = __put_user_fn(&__x, ptr,		\
+					 sizeof(*(ptr)));	\
 		break;						\
 	default:						\
 		__put_user_bad();				\
@@ -161,29 +161,29 @@ extern int __put_user_bad(void) __attrib
 	switch (sizeof(*(ptr))) {				\
 	case 1: {						\
 		unsigned char __x;				\
-		__gu_err = __get_user_fn(sizeof (*(ptr)),	\
-					 ptr, &__x);		\
+		__gu_err = __get_user_fn(&__x, ptr,		\
+					 sizeof(*(ptr)));	\
 		(x) = *(__force __typeof__(*(ptr)) *) &__x;	\
 		break;						\
 	};							\
 	case 2: {						\
 		unsigned short __x;				\
-		__gu_err = __get_user_fn(sizeof (*(ptr)),	\
-					 ptr, &__x);		\
+		__gu_err = __get_user_fn(&__x, ptr,		\
+					 sizeof(*(ptr)));	\
 		(x) = *(__force __typeof__(*(ptr)) *) &__x;	\
 		break;						\
 	};							\
 	case 4: {						\
 		unsigned int __x;				\
-		__gu_err = __get_user_fn(sizeof (*(ptr)),	\
-					 ptr, &__x);		\
+		__gu_err = __get_user_fn(&__x, ptr,		\
+					 sizeof(*(ptr)));	\
 		(x) = *(__force __typeof__(*(ptr)) *) &__x;	\
 		break;						\
 	};							\
 	case 8: {						\
 		unsigned long long __x;				\
-		__gu_err = __get_user_fn(sizeof (*(ptr)),	\
-					 ptr, &__x);		\
+		__gu_err = __get_user_fn(&__x, ptr,		\
+					 sizeof(*(ptr)));	\
 		(x) = *(__force __typeof__(*(ptr)) *) &__x;	\
 		break;						\
 	};							\
@@ -222,7 +222,7 @@ extern int __get_user_bad(void) __attrib
 static inline unsigned long __must_check
 __copy_to_user(void __user *to, const void *from, unsigned long n)
 {
-	return uaccess.copy_to_user(n, to, from);
+	return uaccess.copy_to_user(to, from, n);
 }
 
 #define __copy_to_user_inatomic __copy_to_user
@@ -268,7 +268,7 @@ copy_to_user(void __user *to, const void
 static inline unsigned long __must_check
 __copy_from_user(void *to, const void __user *from, unsigned long n)
 {
-	return uaccess.copy_from_user(n, from, to);
+	return uaccess.copy_from_user(to, from, n);
 }
 
 extern void copy_from_user_overflow(void)
@@ -309,7 +309,7 @@ copy_from_user(void *to, const void __us
 static inline unsigned long __must_check
 __copy_in_user(void __user *to, const void __user *from, unsigned long n)
 {
-	return uaccess.copy_in_user(n, to, from);
+	return uaccess.copy_in_user(to, from, n);
 }
 
 static inline unsigned long __must_check
@@ -326,14 +326,14 @@ static inline long __must_check
 strncpy_from_user(char *dst, const char __user *src, long count)
 {
 	might_fault();
-	return uaccess.strncpy_from_user(count, src, dst);
+	return uaccess.strncpy_from_user(dst, src, count);
 }
 
 static inline unsigned long
 strnlen_user(const char __user * src, unsigned long n)
 {
 	might_fault();
-	return uaccess.strnlen_user(n, src);
+	return uaccess.strnlen_user(src, n);
 }
 
 /**
@@ -359,14 +359,14 @@ strnlen_user(const char __user * src, un
 static inline unsigned long __must_check
 __clear_user(void __user *to, unsigned long n)
 {
-	return uaccess.clear_user(n, to);
+	return uaccess.clear_user(to, n);
 }
 
 static inline unsigned long __must_check
 clear_user(void __user *to, unsigned long n)
 {
 	might_fault();
-	return uaccess.clear_user(n, to);
+	return uaccess.clear_user(to, n);
 }
 
 extern int copy_to_user_real(void __user *dest, void *src, size_t count);
--- a/arch/s390/lib/uaccess_mvcos.c
+++ b/arch/s390/lib/uaccess_mvcos.c
@@ -26,7 +26,7 @@
 #define SLR	"slgr"
 #endif
 
-static size_t copy_from_user_mvcos(size_t size, const void __user *ptr, void *x)
+static size_t copy_from_user_mvcos(void *x, const void __user *ptr, size_t size)
 {
 	register unsigned long reg0 asm("0") = 0x81UL;
 	unsigned long tmp1, tmp2;
@@ -65,7 +65,7 @@ static size_t copy_from_user_mvcos(size_
 	return size;
 }
 
-static size_t copy_to_user_mvcos(size_t size, void __user *ptr, const void *x)
+static size_t copy_to_user_mvcos(void __user *ptr, const void *x, size_t size)
 {
 	register unsigned long reg0 asm("0") = 0x810000UL;
 	unsigned long tmp1, tmp2;
@@ -94,8 +94,8 @@ static size_t copy_to_user_mvcos(size_t
 	return size;
 }
 
-static size_t copy_in_user_mvcos(size_t size, void __user *to,
-				 const void __user *from)
+static size_t copy_in_user_mvcos(void __user *to, const void __user *from,
+				 size_t size)
 {
 	register unsigned long reg0 asm("0") = 0x810081UL;
 	unsigned long tmp1, tmp2;
@@ -117,7 +117,7 @@ static size_t copy_in_user_mvcos(size_t
 	return size;
 }
 
-static size_t clear_user_mvcos(size_t size, void __user *to)
+static size_t clear_user_mvcos(void __user *to, size_t size)
 {
 	register unsigned long reg0 asm("0") = 0x810000UL;
 	unsigned long tmp1, tmp2;
@@ -145,7 +145,7 @@ static size_t clear_user_mvcos(size_t si
 	return size;
 }
 
-static size_t strnlen_user_mvcos(size_t count, const char __user *src)
+static size_t strnlen_user_mvcos(const char __user *src, size_t count)
 {
 	size_t done, len, offset, len_str;
 	char buf[256];
@@ -155,7 +155,7 @@ static size_t strnlen_user_mvcos(size_t
 		offset = (size_t)src & ~PAGE_MASK;
 		len = min(256UL, PAGE_SIZE - offset);
 		len = min(count - done, len);
-		if (copy_from_user_mvcos(len, src, buf))
+		if (copy_from_user_mvcos(buf, src, len))
 			return 0;
 		len_str = strnlen(buf, len);
 		done += len_str;
@@ -164,8 +164,8 @@ static size_t strnlen_user_mvcos(size_t
 	return done + 1;
 }
 
-static size_t strncpy_from_user_mvcos(size_t count, const char __user *src,
-				      char *dst)
+static size_t strncpy_from_user_mvcos(char *dst, const char __user *src,
+				      size_t count)
 {
 	size_t done, len, offset, len_str;
 
@@ -175,7 +175,7 @@ static size_t strncpy_from_user_mvcos(si
 	do {
 		offset = (size_t)src & ~PAGE_MASK;
 		len = min(count - done, PAGE_SIZE - offset);
-		if (copy_from_user_mvcos(len, src, dst))
+		if (copy_from_user_mvcos(dst, src, len))
 			return -EFAULT;
 		len_str = strnlen(dst, len);
 		done += len_str;
--- a/arch/s390/lib/uaccess_pt.c
+++ b/arch/s390/lib/uaccess_pt.c
@@ -22,7 +22,7 @@
 #define SLR	"slgr"
 #endif
 
-static size_t strnlen_kernel(size_t count, const char __user *src)
+static size_t strnlen_kernel(const char __user *src, size_t count)
 {
 	register unsigned long reg0 asm("0") = 0UL;
 	unsigned long tmp1, tmp2;
@@ -42,8 +42,8 @@ static size_t strnlen_kernel(size_t coun
 	return count;
 }
 
-static size_t copy_in_kernel(size_t count, void __user *to,
-			     const void __user *from)
+static size_t copy_in_kernel(void __user *to, const void __user *from,
+			     size_t count)
 {
 	unsigned long tmp1;
 
@@ -211,26 +211,26 @@ fault:
 	return 0;
 }
 
-static size_t copy_from_user_pt(size_t n, const void __user *from, void *to)
+static size_t copy_from_user_pt(void *to, const void __user *from, size_t n)
 {
 	size_t rc;
 
 	if (segment_eq(get_fs(), KERNEL_DS))
-		return copy_in_kernel(n, (void __user *) to, from);
+		return copy_in_kernel((void __user *) to, from, n);
 	rc = __user_copy_pt((unsigned long) from, to, n, 0);
 	if (unlikely(rc))
 		memset(to + n - rc, 0, rc);
 	return rc;
 }
 
-static size_t copy_to_user_pt(size_t n, void __user *to, const void *from)
+static size_t copy_to_user_pt(void __user *to, const void *from, size_t n)
 {
 	if (segment_eq(get_fs(), KERNEL_DS))
-		return copy_in_kernel(n, to, (void __user *) from);
+		return copy_in_kernel(to, (void __user *) from, n);
 	return __user_copy_pt((unsigned long) to, (void *) from, n, 1);
 }
 
-static size_t clear_user_pt(size_t n, void __user *to)
+static size_t clear_user_pt(void __user *to, size_t n)
 {
 	void *zpage = (void *) empty_zero_page;
 	long done, size, ret;
@@ -242,7 +242,7 @@ static size_t clear_user_pt(size_t n, vo
 		else
 			size = n - done;
 		if (segment_eq(get_fs(), KERNEL_DS))
-			ret = copy_in_kernel(n, to, (void __user *) zpage);
+			ret = copy_in_kernel(to, (void __user *) zpage, n);
 		else
 			ret = __user_copy_pt((unsigned long) to, zpage, size, 1);
 		done += size;
@@ -253,7 +253,7 @@ static size_t clear_user_pt(size_t n, vo
 	return 0;
 }
 
-static size_t strnlen_user_pt(size_t count, const char __user *src)
+static size_t strnlen_user_pt(const char __user *src, size_t count)
 {
 	unsigned long uaddr = (unsigned long) src;
 	struct mm_struct *mm = current->mm;
@@ -263,7 +263,7 @@ static size_t strnlen_user_pt(size_t cou
 	if (unlikely(!count))
 		return 0;
 	if (segment_eq(get_fs(), KERNEL_DS))
-		return strnlen_kernel(count, src);
+		return strnlen_kernel(src, count);
 	if (!mm)
 		return 0;
 	done = 0;
@@ -289,8 +289,8 @@ fault:
 	goto retry;
 }
 
-static size_t strncpy_from_user_pt(size_t count, const char __user *src,
-				   char *dst)
+static size_t strncpy_from_user_pt(char *dst, const char __user *src,
+				   size_t count)
 {
 	size_t done, len, offset, len_str;
 
@@ -301,7 +301,7 @@ static size_t strncpy_from_user_pt(size_
 		offset = (size_t)src & ~PAGE_MASK;
 		len = min(count - done, PAGE_SIZE - offset);
 		if (segment_eq(get_fs(), KERNEL_DS)) {
-			if (copy_in_kernel(len, (void __user *) dst, src))
+			if (copy_in_kernel((void __user *) dst, src, len))
 				return -EFAULT;
 		} else {
 			if (__user_copy_pt((unsigned long) src, dst, len, 0))
@@ -315,8 +315,8 @@ static size_t strncpy_from_user_pt(size_
 	return done;
 }
 
-static size_t copy_in_user_pt(size_t n, void __user *to,
-			      const void __user *from)
+static size_t copy_in_user_pt(void __user *to, const void __user *from,
+			      size_t n)
 {
 	struct mm_struct *mm = current->mm;
 	unsigned long offset_max, uaddr, done, size, error_code;
@@ -326,7 +326,7 @@ static size_t copy_in_user_pt(size_t n,
 	int write_user;
 
 	if (segment_eq(get_fs(), KERNEL_DS))
-		return copy_in_kernel(n, to, from);
+		return copy_in_kernel(to, from, n);
 	if (!mm)
 		return n;
 	done = 0;
